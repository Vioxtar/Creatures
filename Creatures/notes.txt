





    // Tip: If you do a lot of custom rendering, you probably want to use your own geometrical types and benefit of overloaded operators, etc.
    // Define IM_VEC2_CLASS_EXTRA in imconfig.h to create implicit conversions between your types and ImVec2/ImVec4.
    // ImGui defines overloaded operators but they are internal to imgui.cpp and not exposed outside (to avoid messing with your types)
    // In this example we are not using the maths operators!



quick roadmap to v 1.0

fix misalignment on window resize
create simplistic creature tracker for sensor debugging
implement sensors
finish energy/life stuff
add mutations 


	SATURATION IS INHERITED
	LIFE CAN BE LESS BORDER OPACITY
	OPACITY IS ENERGY
	RADIUS IS MEAT

	MEAT IS STORED ENERGY, RAISES WHEN MAXIMUM ENERGY IS FILLED AND WE KEEP EATING
	WHEN ENERGY IS BELOW MAXIMUM MEAT SLOWLY TURNS TO ENERGY



	Sensors approach

	Motivations
		1. sensing the world does not require an exploding amount of brain inputs for performance reasons
		2. creatures are able to gather a rich collection of data that is sufficient to describe their enviornment
		3. creatures and the end user see the same data: we dont want the user to be able to see more than creatures, this can lead to an extreme gap between the user's expectations of creature performance to actual creature performance, which results in an overall disappointing user experience
		4. while the average unevolved sensing should be rewarding (important), evolved sensing is even more rewarding
		
	

	When considering the sensor circle/points approaches, we need to choose between:
		1. Less memory access, more computations: bigger uniform grid tile of sense radius dimensions, during in-tile iterations test for senses
		2. More memory access, less computations: we spatial-index the uniform grid based on our sampling positions: but then we STILL have to perform
			computations to test for sensing, only on far less creatures...

	When considering the cone/line approaches, sensing areas span across several uniform tiles so we're forced to go with the first 'less memory access' choice

	One of these options is probably more performant than the other... and its probably the first...? because we're indexing the uniform grid incoherently creature_count * sensor_count times
	Choose first option!


	NON-OBVIOUS-TODOS:
	make the simulation random-seedable!
	Creatures have stick points - if stick A sticks to non-stick surface, it results in 0.25 force, if stick A sticks to stick B and both are active, it results in 1 force
	creatures can move backwards at 0.75 the speed they can move forward
	Have a performance window! Squeeze everything you want into there (FPS counter, FPS plot based on time/creature count, forward propagations stats/etc)
	Use a seperate thread for UI (including callbacks and updates...)
	ADD A GENERATIONS HISTOGRAM (instead of average generations etc)
	Consider adding negated activated functions (like you posted in discord) for maybe even MORE expressive brains!
		But for now... use two-node setups for moving shit linearly
	Create two creature-creating functions: create first gen creature, and create offspring creature
	replace branching code with branchless code
	Consider giving every node its own activation exponent?
	Find if theres a way to pass non-interpolated data to the fragment shader by creature instance
	Implement 'visibilities' SSBO, every frame update each creature's 'LOD' value: false is offscreen, true is visible, then use that for deformations/whatever else
	(Optional) Refactor simulation.cpp by splitting up code (programs, creature SSBOs, etc, just like camera is split up)
	Settings pretty names
	DearImgui integration and UI
		F11 to fullscreen
	Add WINDOW settings in settings file?
	Spikes and shields and stick mechanisms
	Fix window misalignment
	FIX THE WEIRD GHOST BALL AT 0, 0
	Find out why border physics is so damn unstable (not really the case when border restitution is at 0)





	Some notes
	
		RadiusPercentage = 0.3 * LifePercentage + 0.5 * EnergyPercentage + 0.2 * ControlPercentage

	saturation belongs to family
	life reflected by fill

	make stickyness global to creature's body, make A not stick to B if A deflects B with shield or if B deflects A with shield..?

	Creatures control hardness target, and have a stick mechanism (either arms or body or some sort of friction side)

	Sigmoid activation can be described as:

	sigmoidActivation(x) =
		if x == 0.5 then return x
		if x < 0.5 then return ((2x)^a)/2
		if x > 0.5 then return -(((2(1-x))^a) / 2) + 1

	for some constant a = 8-ish

	It could also probably be approximated further by dividing into regions and returning linear functions within those regions

















	Approach to brains:
	We wish to minimize memory complexity of brains with minimal time complexity tradeoffs.
	
	Assume that:
	1. We have about 2 GB of usage space for brains
	2. We want to support up to 100,000 creatures at once

	Some numbers:
		1 GB =~ 250,000,000 floats
		250,000,000 / 100,000 = 2500 floats per creature
		However we about just about 2 GB available, so that's 500,000,000 floats / 100,000 creatures = 5000 floats per creature.
		Going by that number, that gives us just about 4500 floats per brain, leaving us with 500*4 bytes for other attributes.
		

	Some more numbers:
		If we would have 40 nodes in a level, and up to 5 levels, then every link level would have 40^2 = 1600 links, meaning 1600*5 = 8000 total links in the brain. If every link has a scalar float and a bias float, then that's 16000 floats per brain!
		A more feasible scenario is have 60 input nodes, 10 nodes in every hidden level, and 5 levels, that means: 60*10 + 10*10*4 = 1000 links in the entire brain! 2 floats in a link implies 2000 floats, and were we to consider node values, then that's 110 more floats = 2110 floats per brain.
	
		If a sensor each has:
			1. Activation
			2. Hue
			3. Lightness
			4. Saturation
		
		And we have 8 sensors, then that's 4*8 = 32 inputs. 

	To minimize memory complexity we can take several approaches:

		a. Instead of merely defining # of nodes per level (which is always a very big number since inputs is about 40-50 nodes), define # of nodes per hidden level and # of nodes per input level, this will drastically decrease size!
		b. Instead of having every node connect to every other node in the previous layer, have it only connect to X nodes
		c. Don't use biases! Just scalars...

	The overall approach for brains:

		A single brain buffer would contain:

			[STRUCTURE HEADER UINTS | A SEQUENCE OF ALL NODES' CURRENT VALUES | A SEQUENCE OF LINKS]

		The structure header is simply a sequence of uints that tells us the structure of the brain.
			[NUMOFLEVELS = 5, 32, 15, 10, 18, 12] for example means 32 inputs, 3 middle levels (15, 10 and 18 nodes), and 12 outputs.

		The sequence of notes is merely the current values stored at each node. We know that this buffer always starts immediately after
		the structure header, and is exactly sum(structure values) indices long.

		Afterwards, a sequence of links: the length of this buffer is exactly 32*15 + 15*10 + 10*18 + 18*12 indices long.

	We can use this layout to cleverly iterate our brains and perform forward propagations.
	While this layout is borderline dynamic, we must make each total brain size fixed for proper SSBO indexing.
	We can choose one of two data layout approaches:
		
		[FIXED STRUCTURE | DYNAMIC NODES | DYNAMIC LINKS, empty space]
		(gives us more flexibility in how we forward propagate, less convenient for mutation logic)
	
	Or this:

		[FIXED STRUCTURE | FIXED NODES, empty space | FIXED LINKS, empty space]
		(gives us more comfort in mutation handling, less in forward propagations)

	We'll choose the first, since it may prove more flexible to changes in the future (no hard-coding of sub-buffer sizes)

	Finally we wish for a straight forward method to provide an upper bound on memory complexity of brains.
	
