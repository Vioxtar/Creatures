

TRAINING WHEEL PROTOCOL - How to speed up simulation stage zero
Training wheel protocol is active only when a condition such as:
	- max generation is below a certain threshold
	- average generation is below a certain threshold
	- num of different species (?) is below a certain threshold

... is satisfied. If active, the training wheel protocol follows the following procedure:
1. During certain frames of the simulation, gather all creature_OffspringCount data and find the X best creatures that have the highest offspring counts
2. Load highest scoring creatures' brain/device local angles into a queue
3. With high probability, instead of spawning a fully-randomized firstgen, pop a selected creature and spawn a training-wheels creature, mutate its brain and local angles, randomize hue and skin pattern, and throw back into simulation

... all training wheel'd creatures spawn as firstgens. We can keep track of previously spawned training wheel'd creatures and decrement their scores by the number of attempts they've had



Project minimum requiremenets:
	GL_MAX_COMPUTE_SHADER_STORAGE_BLOCKS >= 16



	Roadmap:
	Brain push pull
	Reproduction
	Tweaks for a better evolutionary model
	Brain forward propagate optimization



	SOME NOTES ON REPRODUCTION
	When two creatures assume reproduction position, each creature that has > 0.5 horny creates an offspring with the other, only at the expense of their own energy



	BRAINS PUSH PULL:
	
	Push:
		Pupil sights 1
		Cone sights 1
		Energy 1
		Life 1
		Meat 1
		Body pressure (?) 1
		velocity (what determines 1 / max value? probably set a max velocity value!) 3
			forward node
			backward node
			right node
			left node
		angle velocity (what determines 1 / max value? probably set a max angular velocity value!) 1
			clockwise node
			anti clockwise node
		nodes 1
		structures 1

	Pull:
		Forward
		Backward
		Right
		Left
		Clockwise
		AntiClockwise
		Spike
		Shield
		Feeder
		Hardness
		Radius
		Skin value
		Hornyness
		eye muscles
		cone radii
		pupil cone coverage


	REMOVE FORWARD/TURN THRUSTS AND INSTEAD USE AN 'ACTUATIONS' MODEL:
	ACTUATIONS = {forth, back, right, left, clockwise, anticlockwise, spike, shield, feeder, hardness, radius, skin value, hornyness, eye right, eye left, eye up, eye down, eye cone radius, eye pupil coverage}
	ACTUATIONS DONT NEED TO BE AT SOME BUFFER OF THEIR OWN, WE DIRECTLY USE THE BRAIN OUTPUTS! Yes! This means we also bind brain nodes to body works

	So you do: creature_brain_pull_and_body_works_part1, creature_brain_pull_and_body_works_part2

	PART 1 (focuses on actuations)
	BrainStructures
	BrainNodes
	Lives
	Energies
	ForwardDirections
	RightDirections
	Velocities
	AngleVelocities
	EyeMuscles
	EyeConeRadii
	EyePupilCoverage
	GeneralFloat (write energy cost)

	PART 2 (focuses on body works)
	BrainStructures
	BrainNodes
	Lives
	Energies
	Meats
	Radii
	Hardnesses
	Spikes
	Shields
	Feeders
	SkinValues
	SkinSaturations
	Vanishes
	GeneralFloat (read and apply energy cost + our own)



	eventualRightLeft = (right - left) * uCreatureStrafeMovementEffectiveness
	eventualForthBack = forth * uCreatureForwardMovementEffectiveness + back * uCreatureBackwardMovementEffectiveness
	eventualVelAdd = forwardDir * eventualForthBack + rightDir * eventualRightLeft
	velocity += eventualVelAdd

	energyRemoval = eventualForthBack >= 0 ? forth * uCreatureForwardMovementEnergyCost : back * uCreatureBackwardMovementEnergyCost
	energyRemoval += abs(right - left) * uCreatureStrafeMovementEnergyCost










	How to energy interactions

	use coherent modifier + barrier() function somehow, or...


	collider indices are no longer uint, but isntead uvec2: (bGID, placementIndexInB'sCollidersIndices) so that A can tweak B's collidersEnergyFlow:

	In A's thread:

	for all uvec2(bGID, placement) in A's collider indices:
		ColliderEnergyFlows[bGID + placement] = A's give or take

	Each thread asks: Did I feed someone? Was I spiked by someone?
	And so each thread only handles outward flow of energy!



	.... Actually I'ma probably have to go with the uvec2 idea, all coherent + barrier() can give me is the option not to spread it to part 3...





	// SOLUTION FOR INTERACTIONS START

	Creature interactions
	
	Collision detection

		Total: 15 storage blocks
			poses
			velos
			meat (for mass)
			radii
			hardness
			ugrid
			tiles
			physfix
		
			colliders(deformers)Count // data msngr
			colliderIndices // data msngr
			colliderPosDiffDirs // data msngr
			colliderPositions (already there)
			colliderRadii (already there)

			stickStates
			stickDirs

	Energy flow (12)
		collidersCount[]
		colliderIndices[]
		colliderPosDiffDirs[]
		Meat
		Spike States
		Spike Directions
		Shield States
		Shield Directions
		Shield Spans
		Feeder states
		feeder directions
		energies

	Reproduction (5)
		collidersCount[]
		colliderIndices[]
		colliderPosDiffDirs[]
		Hornyness
		ReproductionLogger
		ForwardDir


		// SOLUTION FOR INTERACTIONS END








	SATURATION IS INHERITED
	LIFE CAN BE LESS BORDER OPACITY
	OPACITY IS ENERGY
	RADIUS IS MEAT

	MEAT IS STORED ENERGY, RAISES WHEN MAXIMUM ENERGY IS FILLED AND WE KEEP EATING
	WHEN ENERGY IS BELOW MAXIMUM MEAT SLOWLY TURNS TO ENERGY

	USE HSV, NOT HSL!

	Sensors approach

	Motivations
		1. sensing the world does not require an exploding amount of brain inputs for performance reasons
		2. creatures are able to gather a rich collection of data that is sufficient to describe their enviornment
		3. creatures and the end user see the same data: we dont want the user to be able to see more than creatures, this can lead to an extreme gap between the user's expectations of creature performance to actual creature performance, which results in an overall disappointing user experience
		4. while the average unevolved sensing should be rewarding (important), evolved sensing is even more rewarding
		
	

	When considering the sensor circle/points approaches, we need to choose between:
		1. Less memory access, more computations: bigger uniform grid tile of sense radius dimensions, during in-tile iterations test for senses
		2. More memory access, less computations: we spatial-index the uniform grid based on our sampling positions: but then we STILL have to perform
			computations to test for sensing, only on far less creatures...

	When considering the cone/line approaches, sensing areas span across several uniform tiles so we're forced to go with the first 'less memory access' choice

	One of these options is probably more performant than the other... and its probably the first...? because we're indexing the uniform grid incoherently creature_count * sensor_count times
	Choose first option!


	NON-OBVIOUS-TODOS:
	use 2 skin hues! one is shown in pattern?
	make patterns more visible
	use namespaces instead of shitty NameSpace_ convention
	go back to non-naive mutation model...
	first gens training wheels: firstgens get special guidance - we make sure to make stronger (but still random) links between eyes and movement, and weak/non-existent links between other nodes
	grid : bunch of triangulated vertices with values in them to be fragmented holding whatever the fuck we want, perhaps a vec3(horomone, )
	rest mechanic: keep a 'rest' float for every creature that interpolations between 0 and 1 based on actuations and shit (high actuations means low rest, low actuations means high rest), have it interpolate to the target very slowly, then base meat to energy conversion on restness: high restness -> high meat to energy conversion
	initial pre-simulation settings 
	checks sequence + a dearIMGUI prompting system (in its own MessagePrompts.cpp)
	creatures cant reproduce unless their meat is above some threshold? Or to be more direct, decouple reproduction energy cost to reproduction energy cost AND reproduction energy threshold!
	have creatures be able to control their device local angles?
	each creature has different energy/meat/life conversion rates? hmmm
	have firstgen spawn rate be affected by the ratio between alive creatures and dead creatures... if there are lots of alive creatures, it means they've got a pretty nice source of food and they should fight each other? meh
	make device effectiveness increase with meat? creatures prefer to reproduce quickly and - yes, die quickly. BUT MAYBE THIS IS BECAUSE YOU'RE GIVING THEM A HIGH LIFE VALUE? A damaged creature is better off reproducing to immediately regain its health at no energy cost!
	have a dynamic firstgen spawn rate to force creatures to evolve to hunt food that actually evades them
	move alpha computation from fragment to vertex shader
	have different selectable (through keyboard numbers!) rendering programs to view special data like:
		energy transactions heatmap
		reproductions
		life heatmaps
		meats heatmap
		generations within histogram heatmap
		TO DO THIS USE A SINGLE PROGRAM THAT SUPPORTS X HEATMAP RATIO WITH MIN/MAX UNIFORMS USED FOR NORMALIZATION, THEN JUST CHANGE BINDINGS AND UNIFORM INPUTS
	creature tracker show creature trail?
	make saturation actually an inherited trait, and have the pupil sight see saturation difference, meanwhile life can be reflected by opacity exponent
	REST MECHANIC: make it so creatures can only spend X energy per frame, and if they actuate themselves too much they wont be able to regenerate - so regenerating creatures will need to move slow / halt
	add body pressures, and pass that as a brain input
	spawn firsgens in the corners
	A potentially massive optimization to forward propagations: Use X for creature ID, and use Y for a sequence of nodes in each level, then perform NumOfLevelsToForwardPropagate dispatches!
			Creatures that no longer have things to forward propagate just return immediately!
	MOST IMPORTANT NOTE::: All your SSBO values are raw, un-normalized values! The only process in which raw values are converted to normalized values, or when normalizes values are converted to raw values, is during brain input, and brain output, respectively!
	Keep UGrid tiles small, and instead increase x/y start/end values! Iterate from the center outwards, return if all cones are filled!
	try changing some brain data to GLhalf
	try changing some indexing data to GLint64
	Use as many fucking memory qualifiers and hints as possible to boost performance
	Make a separate UI thread - make sure that while ImGui is being drawn / other UI stuff calculated, the simulation is running! To avoid undefined behavior, decouple the UI 'data snapshotting' logic into a preliminary step, and only once data was snapshot you can divide into threads! Drawing needs to still be in the correct order... this will be hard.
	Add varying input and output counts for brain creatures - depends on the number of eyes!
	make the simulation random-seedable!
	Creatures have stick points - if stick A sticks to non-stick surface, it results in 0.25 force, if stick A sticks to stick B and both are active, it results in 1 force
	Have a performance window! Squeeze everything you want into there (FPS counter, FPS plot based on time/creature count, forward propagations stats/etc)
	ADD A GENERATIONS HISTOGRAM (instead of average generations etc)
	Consider adding negated activated functions (like you posted in discord) for maybe even MORE expressive brains!
		But for now... use two-node setups for moving shit linearly
	Create two creature-creating functions: create first gen creature, and create offspring creature
	replace branching code with branchless code?
	Implement 'visibilities' SSBO, every frame update each creature's 'LOD' value: false is offscreen, true is visible, then use that for deformations/whatever else
	Settings pretty names
	F11 to fullscreen
	Find out why border physics is so damn unstable (not really the case when border restitution is at 0)





	Some notes
	
		RadiusPercentage = 0.3 * LifePercentage + 0.5 * EnergyPercentage + 0.2 * ControlPercentage

	saturation belongs to family
	life reflected by fill

	make stickyness global to creature's body, make A not stick to B if A deflects B with shield or if B deflects A with shield..?

	Creatures control hardness target, and have a stick mechanism (either arms or body or some sort of friction side)

	Sigmoid activation can be described as:

	sigmoidActivation(x) =
		if x == 0.5 then return x
		if x < 0.5 then return ((2x)^a)/2
		if x > 0.5 then return -(((2(1-x))^a) / 2) + 1

	for some constant a = 8-ish

	It could also probably be approximated further by dividing into regions and returning linear functions within those regions

















	Approach to brains:
	We wish to minimize memory complexity of brains with minimal time complexity tradeoffs.
	
	Assume that:
	1. We have about 2 GB of usage space for brains
	2. We want to support up to 100,000 creatures at once

	Some numbers:
		1 GB =~ 250,000,000 floats
		250,000,000 / 100,000 = 2500 floats per creature
		However we about just about 2 GB available, so that's 500,000,000 floats / 100,000 creatures = 5000 floats per creature.
		Going by that number, that gives us just about 4500 floats per brain, leaving us with 500*4 bytes for other attributes.
		

	Some more numbers:
		If we would have 40 nodes in a level, and up to 5 levels, then every link level would have 40^2 = 1600 links, meaning 1600*5 = 8000 total links in the brain. If every link has a scalar float and a bias float, then that's 16000 floats per brain!
		A more feasible scenario is have 60 input nodes, 10 nodes in every hidden level, and 5 levels, that means: 60*10 + 10*10*4 = 1000 links in the entire brain! 2 floats in a link implies 2000 floats, and were we to consider node values, then that's 110 more floats = 2110 floats per brain.
	
		If a sensor each has:
			1. Activation
			2. Hue
			3. Lightness
			4. Saturation
		
		And we have 8 sensors, then that's 4*8 = 32 inputs. 

	To minimize memory complexity we can take several approaches:

		a. Instead of merely defining # of nodes per level (which is always a very big number since inputs is about 40-50 nodes), define # of nodes per hidden level and # of nodes per input level, this will drastically decrease size!
		b. Instead of having every node connect to every other node in the previous layer, have it only connect to X nodes
		c. Don't use biases! Just scalars...

	The overall approach for brains:

		A single brain buffer would contain:

			[STRUCTURE HEADER UINTS | A SEQUENCE OF ALL NODES' CURRENT VALUES | A SEQUENCE OF LINKS]

		The structure header is simply a sequence of uints that tells us the structure of the brain.
			[NUMOFLEVELS = 5, 32, 15, 10, 18, 12] for example means 32 inputs, 3 middle levels (15, 10 and 18 nodes), and 12 outputs.

		The sequence of notes is merely the current values stored at each node. We know that this buffer always starts immediately after
		the structure header, and is exactly sum(structure values) indices long.

		Afterwards, a sequence of links: the length of this buffer is exactly 32*15 + 15*10 + 10*18 + 18*12 indices long.

	We can use this layout to cleverly iterate our brains and perform forward propagations.
	While this layout is borderline dynamic, we must make each total brain size fixed for proper SSBO indexing.
	We can choose one of two data layout approaches:
		
		[FIXED STRUCTURE | DYNAMIC NODES | DYNAMIC LINKS, empty space]
		(gives us more flexibility in how we forward propagate, less convenient for mutation logic)
	
	Or this:

		[FIXED STRUCTURE | FIXED NODES, empty space | FIXED LINKS, empty space]
		(gives us more comfort in mutation handling, less in forward propagations)

	We'll choose the first, since it may prove more flexible to changes in the future (no hard-coding of sub-buffer sizes)

	Finally we wish for a straight forward method to provide an upper bound on memory complexity of brains.
	
